{
 "metadata": {
  "name": "",
  "signature": "sha256:e0781c0672da855bc0bea01ce1f1f9f098b2a7dc224e6c461e247cb29eba0873"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "import random\n",
      "import timeit\n",
      "from multiprocessing import Pool\n",
      "from pympler.asizeof import asizeof\n",
      "import win32process\n",
      "import win32api\n",
      "from BenchmarkTools import random_substring, BenchmarkTaskInfo, run_benchmark\n",
      "import json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "K = 1000\n",
      "M = K * 1000\n",
      "G = M * 1000\n",
      "\n",
      "DataDir = \"C:\\\\Users\\\\vtsue_000\\\\Documents\\\\IPython Notebooks\\\\IndexedSearchBenchmarks\\\\\"\n",
      "corpuses = [\"corpus_genomic.txt\", \"corpus_english.txt\", \"corpus_chinese.txt\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from st_test_native import SuffixTreeTest as ST1\n",
      "from st_mccreight import STMcCreightTest as ST2\n",
      "from sa_pysuffix import SuffixArrayTest as SA1\n",
      "from sa_linsuffarr import SuffixArrayTest as SA2\n",
      "from fmindexplusplus.src.fmindex_test import FMIndexTest as FM1\n",
      "from fm_index import FMIndexTest as FM2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[2, 12, 7]\n",
        "2 \t-\tzz buzz bazz$\n",
        "12 \t-\tzz$\n",
        "7 \t-\tzz bazz$\n",
        "2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " \t-\tzz buzz bazz$\n",
        "7 \t-\tzz bazz$\n",
        "12 \t-\tzz$\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classes = [ST1, ST2, SA1, SA2, FM1, FM2]\n",
      "output_files = ['result.st_test_native.txt', 'result.st_mccreight.txt', 'result.sa_pysuffix.txt', 'result.sa_linsuffarr.txt', 'result.fm_index_plusplus.txt', 'result.fm_index.txt']\n",
      "#output_files = ['temp.txt','temp.txt','temp.txt','temp.txt','temp.txt','temp.txt']\n",
      "sizes = [64 * K, 128 * K, 256 * K, 512 * K, 1 * M, 2 * M, 4 * M, 8 * M, 16 * M, 32 * M, 64 * M]\n",
      "#sizes = [1 * K]\n",
      "lens = [10]\n",
      "\n",
      "for i in range(0, len(classes)):\n",
      "    C = classes[i]\n",
      "    O = output_files[i]\n",
      "    for corpus in corpuses:\n",
      "        \n",
      "        # FMIndexPlusPlus does not support unicode\n",
      "        if C == FM1 and ((\"english\" in corpus) or (\"chinese\" in corpus)):\n",
      "            continue\n",
      "            \n",
      "        for S in sizes:\n",
      "            \n",
      "            # Suffix Trees will out of memory on more than 8 MB of data\n",
      "            if ((C == ST1) or (C == ST2)) and (S >= (16 * M)):\n",
      "                continue\n",
      "                \n",
      "            # FM1 is impossibly slow past 2 MB of data\n",
      "            if (C == FM2) and (S >= (4 * M)):\n",
      "                continue\n",
      "            \n",
      "            for L in lens:\n",
      "                \n",
      "                \n",
      "                if C == FM2: #Lookups are VERY slow on this structure, limit to 100\n",
      "                    task = BenchmarkTaskInfo(DataDir + corpus, C, S, L, num_searches=10, lookups_per_query=10)\n",
      "                else:\n",
      "                    task = BenchmarkTaskInfo(DataDir + corpus, C, S, L)\n",
      "                \n",
      "                #task = BenchmarkTaskInfo(DataDir + corpus, C, S, L, num_searches=5, lookups_per_query=5)\n",
      "                try:\n",
      "                    result = run_benchmark(task)\n",
      "                except AssertionError as e:\n",
      "                    test_e = e\n",
      "                    raise e\n",
      "                    \n",
      "                with open(O, mode='a+') as output:\n",
      "                    output.write(json.dumps(result) + '\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "print os.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "nt\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}